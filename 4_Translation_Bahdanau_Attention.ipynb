{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "RBHsJDpiYDs7"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saks0106/DeepLearning_NLP/blob/main/4_Translation_Bahdanau_Attention.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf### models\n",
        "import numpy as np### math computations\n",
        "import matplotlib.pyplot as plt### plotting bar chart\n",
        "import sklearn### machine learning library\n",
        "import cv2## image processing\n",
        "from sklearn.metrics import confusion_matrix, roc_curve### metrics\n",
        "import seaborn as sns### visualizations\n",
        "import datetime\n",
        "import pathlib\n",
        "import io\n",
        "import os\n",
        "import re\n",
        "import string\n",
        "import time\n",
        "from numpy import random\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow_probability as tfp\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Layer\n",
        "from tensorflow.keras.layers import (Dense,Flatten,SimpleRNN,InputLayer,Conv1D,Bidirectional,GRU,LSTM,BatchNormalization,Dropout,Input, Embedding,TextVectorization)\n",
        "from tensorflow.keras.losses import BinaryCrossentropy,CategoricalCrossentropy, SparseCategoricalCrossentropy\n",
        "from tensorflow.keras.metrics import Accuracy,TopKCategoricalAccuracy, CategoricalAccuracy, SparseCategoricalAccuracy\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from google.colab import drive\n",
        "from google.colab import files\n",
        "from tensorboard.plugins import projector"
      ],
      "metadata": {
        "id": "C24JKO7LxP3O"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#In the previous books, we had problem of Long term memory ie info from inital blocks gets lost in the final steps and model performs poorly\n",
        "# New problem - take a look around you pad pad pad --> regardez autour de vous [end], here entire input is sent to french block without any connection\n",
        "  # regardez is connected to look but it has no way of knowing it, same for autour and around\n",
        "# We focus on block level connection in input and output and how much every input block affected its every output block ie\n",
        "  # how every block in input affects every block in the output. We use Attention Mechansim"
      ],
      "metadata": {
        "id": "8LmlyNEOXQEw"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preparation"
      ],
      "metadata": {
        "id": "cKg0HdsrYA0S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Download"
      ],
      "metadata": {
        "id": "WgU1Z8fcOSW_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "4hwhov2uvDdo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "728e0dd1-ec36-4610-9e78-32591dab8449"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-07-01 12:59:22--  https://www.manythings.org/anki/fra-eng.zip\n",
            "Resolving www.manythings.org (www.manythings.org)... 173.254.30.110\n",
            "Connecting to www.manythings.org (www.manythings.org)|173.254.30.110|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 7420323 (7.1M) [application/zip]\n",
            "Saving to: ‘fra-eng.zip’\n",
            "\n",
            "fra-eng.zip         100%[===================>]   7.08M  20.2MB/s    in 0.4s    \n",
            "\n",
            "2023-07-01 12:59:23 (20.2 MB/s) - ‘fra-eng.zip’ saved [7420323/7420323]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://www.manythings.org/anki/fra-eng.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip \"/content/fra-eng.zip\" -d \"/content/dataset/\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y-ufBPwn8_ax",
        "outputId": "02ae94e8-92ff-4ba7-9fc3-a286a5a96e51"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/fra-eng.zip\n",
            "  inflating: /content/dataset/_about.txt  \n",
            "  inflating: /content/dataset/fra.txt  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Kaggle Dataset"
      ],
      "metadata": {
        "id": "RBHsJDpiYDs7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install -q kaggle\n",
        "# !mkdir ~/.kaggle\n",
        "# !cp kaggle.json ~/.kaggle/\n",
        "# !chmod 600 /root/.kaggle/kaggle.json\n",
        "# !kaggle datasets download -d dhruvildave/en-fr-translation-dataset"
      ],
      "metadata": {
        "id": "0Lako-uhxy-n"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !unzip \"/content/en-fr-translation-dataset.zip\" -d \"/content/dataset/\""
      ],
      "metadata": {
        "id": "B44hfX_vxzA-"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset = tf.data.experimental.CsvDataset(\n",
        "#   \"/content/dataset/en-fr.csv\",\n",
        "#   [\n",
        "#     tf.string,\n",
        "#     tf.string\n",
        "#   ],\n",
        "# )"
      ],
      "metadata": {
        "id": "fXcOEWp2L7U9"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Processing"
      ],
      "metadata": {
        "id": "omyb2Dq_YHbT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_dataset=tf.data.TextLineDataset(\"/content/dataset/fra.txt\")"
      ],
      "metadata": {
        "id": "ywC7WnoIJeXl"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "VOCAB_SIZE=20000\n",
        "ENGLISH_SEQUENCE_LENGTH=64\n",
        "FRENCH_SEQUENCE_LENGTH=64\n",
        "EMBEDDING_DIM=300\n",
        "BATCH_SIZE=64"
      ],
      "metadata": {
        "id": "QlcJxz6cJeb_"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "english_vectorize_layer=TextVectorization(\n",
        "    standardize='lower_and_strip_punctuation',\n",
        "    max_tokens=VOCAB_SIZE,\n",
        "    output_mode='int',\n",
        "    output_sequence_length=ENGLISH_SEQUENCE_LENGTH\n",
        ")"
      ],
      "metadata": {
        "id": "TePer9o-JeeR"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "french_vectorize_layer=TextVectorization(\n",
        "    standardize='lower_and_strip_punctuation',\n",
        "    max_tokens=VOCAB_SIZE,\n",
        "    output_mode='int',\n",
        "    output_sequence_length=FRENCH_SEQUENCE_LENGTH\n",
        ")"
      ],
      "metadata": {
        "id": "unGn0zqEJegg"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def selector(input_text):\n",
        "  split_text=tf.strings.split(input_text,'\\t')\n",
        "  return {'input_1':split_text[0:1],'input_2':'starttoken '+split_text[1:2]},split_text[1:2]+' endtoken'"
      ],
      "metadata": {
        "id": "iNK3uewuQTjY"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "split_dataset=text_dataset.map(selector)"
      ],
      "metadata": {
        "id": "YZDH8xn7Q12e"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in split_dataset.take(3):\n",
        "  print(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TikfuLa5d0Fm",
        "outputId": "bd7f880b-a7cd-4167-ba9f-ddc524d73f34"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "({'input_1': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Go.'], dtype=object)>, 'input_2': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'starttoken Va !'], dtype=object)>}, <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Va ! endtoken'], dtype=object)>)\n",
            "({'input_1': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Go.'], dtype=object)>, 'input_2': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'starttoken Marche.'], dtype=object)>}, <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Marche. endtoken'], dtype=object)>)\n",
            "({'input_1': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Go.'], dtype=object)>, 'input_2': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'starttoken En route !'], dtype=object)>}, <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'En route ! endtoken'], dtype=object)>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def separator(input_text):\n",
        "  split_text=tf.strings.split(input_text,'\\t')\n",
        "  return split_text[0:1],'starttoken '+split_text[1:2]+' endtoken'"
      ],
      "metadata": {
        "id": "7fcSDED_2c-z"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "init_dataset=text_dataset.map(separator)"
      ],
      "metadata": {
        "id": "ktN95hiN2pgU"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in init_dataset.take(3):\n",
        "  print(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OQkSkpd1tils",
        "outputId": "3fa2bfe3-4a58-4937-a079-894c1a9428be"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(<tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Go.'], dtype=object)>, <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'starttoken Va ! endtoken'], dtype=object)>)\n",
            "(<tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Go.'], dtype=object)>, <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'starttoken Marche. endtoken'], dtype=object)>)\n",
            "(<tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Go.'], dtype=object)>, <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'starttoken En route ! endtoken'], dtype=object)>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "english_training_data=init_dataset.map(lambda x,y:x)### input x,y and output x\n",
        "english_vectorize_layer.adapt(english_training_data)#### adapt the vectorize_layer to the training data"
      ],
      "metadata": {
        "id": "_usEDYiOJeil"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "french_training_data=init_dataset.map(lambda x,y:y)### input x,y,z and output y\n",
        "french_vectorize_layer.adapt(french_training_data)#### adapt the vectorize_layer to the training data"
      ],
      "metadata": {
        "id": "dl7pxJprJek2"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def vectorizer(inputs,output):\n",
        "  return {'input_1':english_vectorize_layer(inputs['input_1']),\n",
        "          'input_2':french_vectorize_layer(inputs['input_2'])},french_vectorize_layer(output)"
      ],
      "metadata": {
        "id": "4yVIMxvTJemt"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "split_dataset"
      ],
      "metadata": {
        "id": "op5UqhS14HHz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2e3477b-e035-41de-c5de-fe20d4843507"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_MapDataset element_spec=({'input_1': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'input_2': TensorSpec(shape=(None,), dtype=tf.string, name=None)}, TensorSpec(shape=(None,), dtype=tf.string, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset=split_dataset.map(vectorizer)"
      ],
      "metadata": {
        "id": "wI9-GPpVJepF"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in split_dataset.take(3):\n",
        "  print(i)"
      ],
      "metadata": {
        "id": "m_6Xtks8wPk5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "338b0945-f3a0-4d37-fbc6-75af9e323503"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "({'input_1': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Go.'], dtype=object)>, 'input_2': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'starttoken Va !'], dtype=object)>}, <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Va ! endtoken'], dtype=object)>)\n",
            "({'input_1': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Go.'], dtype=object)>, 'input_2': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'starttoken Marche.'], dtype=object)>}, <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Marche. endtoken'], dtype=object)>)\n",
            "({'input_1': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Go.'], dtype=object)>, 'input_2': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'starttoken En route !'], dtype=object)>}, <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'En route ! endtoken'], dtype=object)>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in dataset.take(1):\n",
        "  print(i)"
      ],
      "metadata": {
        "id": "FM9aenklufpC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65ca17c2-d1ac-4cca-8e85-5d79516b42e8"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "({'input_1': <tf.Tensor: shape=(1, 64), dtype=int64, numpy=\n",
            "array([[44,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]])>, 'input_2': <tf.Tensor: shape=(1, 64), dtype=int64, numpy=\n",
            "array([[  2, 104,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]])>}, <tf.Tensor: shape=(1, 64), dtype=int64, numpy=\n",
            "array([[104,   3,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]])>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "id": "iOpSsko7TiKd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5dd18449-e57f-45de-ceba-5987a2f6c075"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_MapDataset element_spec=({'input_1': TensorSpec(shape=(None, 64), dtype=tf.int64, name=None), 'input_2': TensorSpec(shape=(None, 64), dtype=tf.int64, name=None)}, TensorSpec(shape=(None, 64), dtype=tf.int64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset=dataset.shuffle(2048).unbatch().batch(BATCH_SIZE).prefetch(buffer_size=tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "_WE0s6p9TiM9"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "id": "tTkF_Qu54QB5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36c1bd83-efe5-40dd-929b-f7eab85c9972"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_PrefetchDataset element_spec=({'input_1': TensorSpec(shape=(None, 64), dtype=tf.int64, name=None), 'input_2': TensorSpec(shape=(None, 64), dtype=tf.int64, name=None)}, TensorSpec(shape=(None, 64), dtype=tf.int64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_BATCHES=int(200000/BATCH_SIZE)"
      ],
      "metadata": {
        "id": "K5JXDdrNtwRj"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset=dataset.take(int(0.9*NUM_BATCHES))\n",
        "val_dataset=dataset.skip(int(0.9*NUM_BATCHES))"
      ],
      "metadata": {
        "id": "XQvg18V5TiO7"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset"
      ],
      "metadata": {
        "id": "tfCmn1DzTiRp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d30a5ca8-edb3-4cb3-a2c3-a982172acc95"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_TakeDataset element_spec=({'input_1': TensorSpec(shape=(None, 64), dtype=tf.int64, name=None), 'input_2': TensorSpec(shape=(None, 64), dtype=tf.int64, name=None)}, TensorSpec(shape=(None, 64), dtype=tf.int64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modeling"
      ],
      "metadata": {
        "id": "nBVM2EB0Xh97"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Encoder"
      ],
      "metadata": {
        "id": "hABAiQjTsf5p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# VOCAB_SIZE=20000\n",
        "# ENGLISH_SEQUENCE_LENGTH=64\n",
        "# FRENCH_SEQUENCE_LENGTH=64\n",
        "# EMBEDDING_DIM=300\n",
        "# BATCH_SIZE=64"
      ],
      "metadata": {
        "id": "QeakLZmfhGB1"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "  def __init__(self,vocab_size,embedding_dim,units): #20000,256,\n",
        "    super(Encoder,self).__init__()\n",
        "    self.embedding_dim=embedding_dim\n",
        "    self.vocab_size=vocab_size\n",
        "    self.units=units\n",
        "\n",
        "  def build(self,input_shape): #building the input skeleton block\n",
        "    self.embedding=Embedding(self.vocab_size,self.embedding_dim)\n",
        "    self.lstm=LSTM(self.units,return_sequences=True) # play with using Bi-directioanl, GRU, return_sequences will give output from all blocks\n",
        "\n",
        "  def call(self,x): # input passed in embedding and making weights ready to be passed\n",
        "    x=self.embedding(x)\n",
        "    output=self.lstm(x)\n",
        "    return output"
      ],
      "metadata": {
        "id": "o7LmYWQ2cwaq"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "HIDDEN_UNITS=127 #for lstm\n",
        "EMBEDDING_DIM=256  #for embedding\n",
        "encoder=Encoder(VOCAB_SIZE,EMBEDDING_DIM,HIDDEN_UNITS) #20000,256,127 #build\n",
        "encoder_output=encoder(tf.zeros([128,8])) #this is input (batch, sequence length)-> no of blocks each having a dims of 256 #cal;\n",
        "print(encoder_output.shape)\n",
        "\n",
        "#till now every weight has dims of 256 from every block. Now this will be passed through a fully connected layer and reduce dims to 32\n",
        "#we have batch of 128, blocks of 8 and each block dims is 127 and every block will produce 127 dims"
      ],
      "metadata": {
        "id": "_7ulQFtecwdU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac067afc-c6e3-4e39-deba-38f3cc5e636e"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(128, 8, 127)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bahdanau Attention\n",
        "\n",
        "Output from Above will be Received in Attention"
      ],
      "metadata": {
        "id": "tGJkopfjshmf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.expand_dims([1,2,3,4,5,5],axis=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ms_XeCQjYdms",
        "outputId": "62e4f31b-5e7e-456b-8f6a-862c1d4e5bb3"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(6, 1), dtype=int32, numpy=\n",
              "array([[1],\n",
              "       [2],\n",
              "       [3],\n",
              "       [4],\n",
              "       [5],\n",
              "       [5]], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class BahdanauAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self,units): #256\n",
        "    super(BahdanauAttention,self).__init__()\n",
        "    self.units=units #256\n",
        "\n",
        "  def build(self,input_shape): # 256 dims from prev step is passed into dense layer to learn patterns\n",
        "    \"\"\"\n",
        "    Creating Hiddens layers\n",
        "    \"\"\"\n",
        "    self.w_1=tf.keras.layers.Dense(self.units) #256,  from decoder having shape (batch,32) comes into encoder pass through hidden layer of 256 units\n",
        "    self.w_2=tf.keras.layers.Dense(self.units) #256,    127 dims from above will pass through FCL of 256--> 32\n",
        "    self.w=tf.keras.layers.Dense(1) #Encoder output ie Decoder and Ecoder matrix multiplication and output single values\n",
        "\n",
        "  def call(self,prev_dec_state,enc_states): # previous state of 256, new enc_states of 32\n",
        "    \"\"\"\n",
        "    prev_dec_state is Decoder block before passing weights to next block is passed here ie dense layer\n",
        "    \"\"\"\n",
        "    scores=self.w(tf.nn.tanh(\n",
        "                  self.w_1(tf.expand_dims(prev_dec_state,-2)) +  #here (batch,32)--> (batch,1,32) as encoder output is (128,8,127)\n",
        "                  self.w_2(enc_states))# (batch,8,32)\n",
        "                  ) # from decoder shape is (batch,1,32) and encoder shape is (batch,8,32)\n",
        "\n",
        "        #because tanh goes in self.w --> single outputs in scores as list and this will be passed into softmax to tell which\n",
        "          #word in decoder has highest probability with encoder word\n",
        "        # call fn will take embedding from Encoder, change dims to eg 32, same dims from Decoder,matmul, update weights and give single output as self.w.\n",
        "        # we want self.w score should be equal to 1, so we use softmax below\n",
        "        # self.w will be now passed again and again to subsequent words in Decoder\n",
        "        # shape of self.w will be (batch,no of blocks, 1) 1 for single value of self.w\n",
        "\n",
        "    # check shapes of below variables\n",
        "    attention_weights=tf.nn.softmax(scores,axis=1) # word in output that corresponds to input, give max weightage to that word/scores\n",
        "    #attention_weights shape is (batch,8,1),\n",
        "    context_vector=attention_weights*enc_states  #now we again multiple by original enc_states(batch,8,32) ==> shape of (batch,8,32)\n",
        "    print(context_vector.shape)\n",
        "    context_vector=tf.reduce_sum(context_vector,axis=1) #(batch,8,32) --> vector of dims 256 and ready to be passed in decoder next block as single value\n",
        "    print(context_vector.shape) # this will be passed from bottom in decoder\n",
        "    return context_vector,attention_weights"
      ],
      "metadata": {
        "id": "qD-2QY-YcwgM"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bahdanau_attention=BahdanauAttention(256)\n",
        "context_vector,attention_weights=bahdanau_attention(tf.zeros([128,32]),tf.zeros([128,8,32])) # prev_dec_state(256), enc_states(32)\n",
        "print(context_vector.shape)\n",
        "print(attention_weights.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "naL8ZNDscwme",
        "outputId": "ec07022e-3178-4513-e950-11ba5a25b440"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(128, 8, 32)\n",
            "(128, 32)\n",
            "(128, 32)\n",
            "(128, 8, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Decoder"
      ],
      "metadata": {
        "id": "ETCM23b6sktH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "  def __init__(self,vocab_size,embedding_dim,dec_units,sequence_length):\n",
        "    super(Decoder,self).__init__()\n",
        "    self.embedding_dim=embedding_dim\n",
        "    self.vocab_size=vocab_size\n",
        "    self.dec_units=dec_units\n",
        "    self.sequence_length=sequence_length\n",
        "\n",
        "  def build(self,input_shape):\n",
        "    self.dense=Dense(self.vocab_size,activation=\"softmax\") # output from decoder block, ie output from top having same dims as vocab size\n",
        "    self.gru=GRU(self.dec_units,return_sequences=True,return_state=True)\n",
        "    self.attention=BahdanauAttention(self.dec_units) # as input vectors will enter into every single block\n",
        "    self.embedding=Embedding(self.vocab_size,self.embedding_dim) # french words from bottom\n",
        "\n",
        "\n",
        "  def call(self,x,hidden,shifted_target): #shifted_target are decoder blocks ie actual word getting passed into that block\n",
        "    outputs=[]\n",
        "    context_vectors=[]\n",
        "    attention_weightss=[]\n",
        "    shifted_target=self.embedding(shifted_target)  # create embedding for every block in output\n",
        "\n",
        "    for t in range(0,self.sequence_length): # actual embedding layers\n",
        "      context_vector,attention_weights=self.attention(hidden,x) # hidden is previous word encoding, x is input layer encoding ie initial 8 embedding dims(encoder output)\n",
        "      dec_input=context_vector+shifted_target[:,t] # context_vector(x) is input encoding, shifted_target[:t] is only passing a specific word of that block, both are combined and passed from the bottom\n",
        "      # encoder dims + actual word vector dims\n",
        "\n",
        "      output,hidden=self.gru(tf.expand_dims(dec_input,1)) # gru takes 3D inputs, output of this block(from top--> encoder) is now saved, hidden passed from left\n",
        "      #decoder input is now passed in gru\n",
        "      outputs.append(output[:,0]) #output has shape->,batch_size,units\n",
        "\n",
        "    outputs=tf.convert_to_tensor(outputs) #sequence_length,batch,units ie sequence_length will be auto added\n",
        "    outputs=tf.transpose(outputs, perm=[1,0,2]) # we want batch_size,sequence_length,units so we do transpose\n",
        "\n",
        "    outputs=self.dense(outputs) #vocab size, softmax\n",
        "    return outputs,attention_weights"
      ],
      "metadata": {
        "id": "QMwWra7_cwpc"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decoder=Decoder(VOCAB_SIZE,EMBEDDING_DIM,HIDDEN_UNITS,FRENCH_SEQUENCE_LENGTH)\n",
        "outputs,attention_weights=decoder(encoder_output,tf.zeros([128,HIDDEN_UNITS]),tf.zeros([128,64]))\n",
        "print(outputs.shape)\n",
        "print(attention_weights.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 554
        },
        "id": "qp9SVaGRcwr-",
        "outputId": "e99d5f25-0614-4652-e41d-e4a9a65049df"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(128, 8, 127)\n",
            "(128, 127)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-57-52347afe6d51>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVOCAB_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mEMBEDDING_DIM\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mHIDDEN_UNITS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mFRENCH_SEQUENCE_LENGTH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mattention_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mHIDDEN_UNITS\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_weights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-56-66cf09025c91>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, x, hidden, shifted_target)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequence_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# actual embedding layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m       \u001b[0mcontext_vector\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mattention_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# hidden is previous word encoding, x is input layer encoding ie initial 8 embedding dims(encoder output)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m       \u001b[0mdec_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcontext_vector\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mshifted_target\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# context_vector(x) is input encoding, shifted_target[:t] is only passing a specific word of that block, both are combined and passed from the bottom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m       \u001b[0;31m# encoder dims + actual word vector dims\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Exception encountered when calling layer 'decoder_2' (type Decoder).\n\n{{function_node __wrapped__AddV2_device_/job:localhost/replica:0/task:0/device:GPU:0}} required broadcastable shapes [Op:AddV2]\n\nCall arguments received by layer 'decoder_2' (type Decoder):\n  • x=tf.Tensor(shape=(128, 8, 127), dtype=float32)\n  • hidden=tf.Tensor(shape=(128, 127), dtype=float32)\n  • shifted_target=tf.Tensor(shape=(128, 64), dtype=float32)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### ENCODER\n",
        "input = Input(shape=(ENGLISH_SEQUENCE_LENGTH,), dtype=\"int64\", name=\"input_1\")\n",
        "encoder=Encoder(VOCAB_SIZE,EMBEDDING_DIM,HIDDEN_UNITS)\n",
        "encoder_output=encoder(input)\n",
        "\n",
        "### DECODER\n",
        "shifted_target=Input(shape=(FRENCH_SEQUENCE_LENGTH,), dtype=\"int64\", name=\"input_2\")\n",
        "decoder=Decoder(VOCAB_SIZE,EMBEDDING_DIM,HIDDEN_UNITS,FRENCH_SEQUENCE_LENGTH)\n",
        "decoder_output,attention_weightss=decoder(encoder_output,tf.zeros([1,HIDDEN_UNITS]),shifted_target) #tf.zeros([1,HIDDEN_UNITS]) is needed becuase previous hidden state doesn't exist in output ie [start]\n",
        "\n",
        "### OUTPUT\n",
        "bahdanau=Model([input,shifted_target],decoder_output)\n",
        "bahdanau.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q3O-AVFzcwup",
        "outputId": "2779625c-d777-449b-c2d5-efac99296e57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_10\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 64)]         0           []                               \n",
            "                                                                                                  \n",
            " encoder_8 (Encoder)            (None, 64, 256)      5645312     ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, 64)]         0           []                               \n",
            "                                                                                                  \n",
            " decoder_18 (Decoder)           ((None, 64, 20000),  10786593    ['encoder_8[0][0]',              \n",
            "                                 (None, 64, 1))                   'input_2[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 16,431,905\n",
            "Trainable params: 16,431,905\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class BLEU(tf.keras.metrics.Metric):\n",
        "    def __init__(self,name='bleu_score'):\n",
        "        super(BLEU,self).__init__()\n",
        "        self.bleu_score=0\n",
        "\n",
        "    def update_state(self,y_true,y_pred,sample_weight=None):\n",
        "      y_pred=tf.argmax(y_pred,-1)\n",
        "      self.bleu_score=0\n",
        "      for i,j in zip(y_pred,y_true):\n",
        "        tf.autograph.experimental.set_loop_options()\n",
        "\n",
        "        total_words=tf.math.count_nonzero(i)\n",
        "        total_matches=0\n",
        "        for word in i:\n",
        "          if word==0:\n",
        "            break\n",
        "          for q in range(len(j)):\n",
        "            if j[q]==0:\n",
        "              break\n",
        "            if word==j[q]:\n",
        "              total_matches+=1\n",
        "              j=tf.boolean_mask(j,[False if y==q else True for y in range(len(j))])\n",
        "              break\n",
        "\n",
        "        self.bleu_score+=total_matches/total_words\n",
        "\n",
        "    def result(self):\n",
        "        return self.bleu_score/BATCH_SIZE"
      ],
      "metadata": {
        "id": "HIzOQNEucwyG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bahdanau.compile(\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "    optimizer=tf.keras.optimizers.Adam(5e-4),\n",
        "    metrics=[BLEU()],\n",
        "    run_eagerly=True)"
      ],
      "metadata": {
        "id": "Oe0WGqZmcxGp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_filepath = '/content/drive/MyDrive/nlp/translation/bahdanau_attention_1.h5'\n",
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath,\n",
        "    monitor='val_loss',\n",
        "    mode='min',\n",
        "    save_best_only=True)"
      ],
      "metadata": {
        "id": "Tai1ZEi1cxJn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history=bahdanau.fit(\n",
        "    train_dataset,\n",
        "    validation_data=val_dataset,\n",
        "    epochs=30,)\n",
        "    #callbacks=[model_checkpoint_callback])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 919
        },
        "id": "5VUmxwl5e8pl",
        "outputId": "13218bc3-7a02-4f59-d6c3-97035337a50c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "2812/2812 [==============================] - 790s 281ms/step - loss: 0.3764 - val_loss: 0.8106\n",
            "Epoch 2/30\n",
            "2812/2812 [==============================] - 784s 279ms/step - loss: 0.2681 - val_loss: 0.6852\n",
            "Epoch 3/30\n",
            "2812/2812 [==============================] - 781s 278ms/step - loss: 0.2046 - val_loss: 0.6187\n",
            "Epoch 4/30\n",
            "2812/2812 [==============================] - 781s 278ms/step - loss: 0.1673 - val_loss: 0.5875\n",
            "Epoch 5/30\n",
            "2812/2812 [==============================] - 779s 277ms/step - loss: 0.1427 - val_loss: 0.5829\n",
            "Epoch 6/30\n",
            "2812/2812 [==============================] - 779s 277ms/step - loss: 0.1251 - val_loss: 0.5645\n",
            "Epoch 7/30\n",
            "2812/2812 [==============================] - 777s 276ms/step - loss: 0.1119 - val_loss: 0.5586\n",
            "Epoch 8/30\n",
            "2812/2812 [==============================] - 777s 276ms/step - loss: 0.1016 - val_loss: 0.5745\n",
            "Epoch 9/30\n",
            "2812/2812 [==============================] - 780s 277ms/step - loss: 0.0932 - val_loss: 0.5652\n",
            "Epoch 10/30\n",
            "2812/2812 [==============================] - 772s 275ms/step - loss: 0.0863 - val_loss: 0.5628\n",
            "Epoch 11/30\n",
            "2812/2812 [==============================] - 764s 271ms/step - loss: 0.0801 - val_loss: 0.5629\n",
            "Epoch 12/30\n",
            "2812/2812 [==============================] - 771s 274ms/step - loss: 0.0750 - val_loss: 0.5794\n",
            "Epoch 13/30\n",
            "2812/2812 [==============================] - 772s 274ms/step - loss: 0.0704 - val_loss: 0.5928\n",
            "Epoch 14/30\n",
            "2812/2812 [==============================] - 773s 275ms/step - loss: 0.0663 - val_loss: 0.5830\n",
            "Epoch 15/30\n",
            "2812/2812 [==============================] - 772s 274ms/step - loss: 0.0628 - val_loss: 0.5979\n",
            "Epoch 16/30\n",
            "1593/2812 [===============>..............] - ETA: 5:03 - loss: 0.0493"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-122-80ef07eaaa65>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     epochs=30,)\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;31m#callbacks=[model_checkpoint_callback])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1387\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1388\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1389\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    436\u001b[0m     \"\"\"\n\u001b[1;32m    437\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 438\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    295\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m       raise ValueError(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    316\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m       \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m       \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1032\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1034\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1035\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1104\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1105\u001b[0m       \u001b[0;31m# Only block async when verbose = 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1106\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1107\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36msync_to_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    561\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 563\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    912\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 914\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    915\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    912\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 914\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    915\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    555\u001b[0m     \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 557\u001b[0;31m       \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    558\u001b[0m     \u001b[0;31m# Strings, ragged and sparse tensors don't have .item(). Return them as-is.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeneric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1221\u001b[0m     \"\"\"\n\u001b[1;32m   1222\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1223\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1224\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1187\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1189\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1190\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1191\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model_loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "5c5A7_pudzP8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "\n",
        "plt.title('model_accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "PsF_wos17EOC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bahdanau.evaluate(val_dataset)"
      ],
      "metadata": {
        "id": "z67BesEQ7EQC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df808b85-3fc4-43d9-c2d7-996de960cfc8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "274/274 [==============================] - 1865s 7s/step - loss: 0.7017 - bleu_1: 0.1561\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7016859650611877, 0.15608372877928317]"
            ]
          },
          "metadata": {},
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing"
      ],
      "metadata": {
        "id": "4i1ajAymaDoF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "index_to_word={x:y for x, y in zip(range(len(french_vectorize_layer.get_vocabulary())),\n",
        "                                   french_vectorize_layer.get_vocabulary())}"
      ],
      "metadata": {
        "id": "b5vMnTM62Cx_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def translator(english_sentence):\n",
        "  tokenized_english_sentence=english_vectorize_layer([english_sentence])\n",
        "  shifted_target='starttoken'\n",
        "\n",
        "  for i in range(FRENCH_SEQUENCE_LENGTH):\n",
        "    tokenized_shifted_target=french_vectorize_layer([shifted_target])\n",
        "    output=bahdanau.predict([tokenized_english_sentence,tokenized_shifted_target])\n",
        "    french_word_index=tf.argmax(output,axis=-1)[0][i].numpy()\n",
        "    current_word=index_to_word[french_word_index]\n",
        "    if current_word=='endtoken':\n",
        "      break\n",
        "    shifted_target+=' '+current_word\n",
        "  return shifted_target[11:]"
      ],
      "metadata": {
        "id": "HiWzshkMKfQg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "translator('What makes you think that is not true?')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "0RYy2vtxKfS7",
        "outputId": "43f4c316-bc05-4356-839f-31a64d5ae448"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'questce qui te fait croire que ce nest pas vrai'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "translator('Have you ever watched a soccer under the rain?')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ymusGWncm6sr",
        "outputId": "70b2058b-10c2-4397-b203-f125f1504eab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'astu déjà regardé un match de la pluie'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "translator('Great trees do not grow with ease, the stronger the winds, the stronger the trees')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "M6y34Nhv79U_",
        "outputId": "a4087669-80ec-4aeb-8584-bb082146cf70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'des arbres sont très [UNK] pas fort'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "translator('Everyone should water his or her tomato plants')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "VDfIbnVL79XE",
        "outputId": "343e6c47-6838-4ffb-da7b-eab93e0c0240"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'tout le monde devrait manger sa propriété à la nage'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_to_index={y:x for x, y in zip(range(len(french_vectorize_layer.get_vocabulary())),\n",
        "                                   french_vectorize_layer.get_vocabulary())}"
      ],
      "metadata": {
        "id": "f1BQFbrdKfVZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ih75R554nENx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}